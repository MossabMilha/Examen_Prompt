# ğŸ’¡ TP Prompt Engineering â€” Oumayma Mesbahi

Ce projet explore le rÃ´le du **Prompt Engineering** dans l'utilisation d'IA gÃ©nÃ©rative pour le dÃ©veloppement logiciel. Ã€ travers une sÃ©rie d'exercices, nous Ã©valuons lâ€™impact de diffÃ©rents types de prompts sur la qualitÃ©, la robustesse, et la professionnalisation du code gÃ©nÃ©rÃ©.

---

## ğŸ§  Partie 1 : Choix de la Solution d'IA GÃ©nÃ©rative

### âœ… 1. Solution Choisie
> **Gemini (anciennement Bard)** â€” modÃ¨le LLM avancÃ© de Google, utilisÃ© via une interface de chat.

### ğŸ“Œ 2. DÃ©finition BrÃ¨ve
IA gÃ©nÃ©rative capable de comprendre et produire du **langage naturel** et du **code**. Elle fonctionne comme un assistant conversationnel polyvalent pour :
- GÃ©nÃ©ration de code
- DÃ©bogage
- Documentation
- Refactoring

### âš™ï¸ 3. Avantages
- **Prototypage rapide** : GÃ©nÃ¨re des structures de code ou des applications simples.
- **Assistance au dÃ©bogage** : Analyse dâ€™erreurs (tracebacks), suggestions dâ€™algorithmes.
- **Documentation et tests automatisÃ©s** : RÃ©daction de docstrings, README, et tests unitaires.

### âš ï¸ 4. InconvÃ©nients
- **Hallucinations** : Code inventÃ© ou logiquement erronÃ©.
- **SensibilitÃ© au contexte** : Les rÃ©ponses dÃ©pendent de la clartÃ© du prompt.
- **Obsolescence** : Non informÃ©e des mises Ã  jour rÃ©centes sans contexte explicite.

### ğŸ§° 5. Cas dâ€™Usage Typiques
- Refactoring
- Traduction de code entre langages
- Apprentissage (explication de concepts, bibliothÃ¨ques, etc.)

---

## ğŸ§ª Partie 2 : GÃ©nÃ©ration de Code avec l'IA

### ğŸ” Exercice 2.1 â€” Vague vs. SpÃ©cifique vs. Persona

#### âš« Prompt Vague
- Fonction gÃ©nÃ©rÃ©e : `effectuer_operation`
- OpÃ©rations : +, -, *, /
- Gestion dâ€™erreurs basique (ex : division par zÃ©ro, opÃ©rateur invalide)
- Bon docstring et commentaires

#### âš« Prompt SpÃ©cifique
- Meilleure **lisibilitÃ©** et **documentation**
- Respect des exigences : nom `calculate`, arrondi Ã  2 dÃ©cimales
- Toujours mÃªme dÃ©faut de gestion dâ€™erreurs (retour de str au lieu de `raise`)

#### âš« Prompt Persona
- Apparence trÃ¨s professionnelle
  - Type hinting
  - Bloc `if __name__ == "__main__"`
  - Doctest dans le docstring
- Structure soignÃ©e mais **mÃªme erreur critique** (str au lieu dâ€™exception)

#### ğŸ” SynthÃ¨se de lâ€™Exercice
- **SpÃ©cificitÃ©** : Meilleur impact fonctionnel
- **Persona** : Meilleur style et structure
- **Failles persistantes** : Mauvaise gestion des erreurs dans toutes les versions

---

### ğŸ”§ Exercice 2.2 â€” Zero-shot vs One-shot vs Few-shot

#### âš« Zero-Shot
- InterprÃ©tation ambigÃ¼e : mauvaise rÃ¨gle dâ€™insertion de tirets
- TrÃ¨s bonne gestion des erreurs (`raise ValueError`)
- Fonctionnel mais possiblement incorrect

#### âš« One-Shot (avec exemple)
- AmbiguÃ¯tÃ© levÃ©e
- RÃ©sultat conforme aux attentes
- Lâ€™exemple simplifie et **oriente correctement la logique mÃ©tier**

#### âš« Few-Shot (avec multiples exemples)
- Renforce la robustesse de la gÃ©nÃ©ration
- Ne change pas le code final (dÃ©jÃ  robuste)
- RÃ©duit les risques dâ€™interprÃ©tation incorrecte

#### ğŸ” Analyse Critique
- Lâ€™ajout dâ€™exemples :
  - Clarifie les rÃ¨gles complexes
  - Renforce les bonnes pratiques
- Le **Few-Shot** est particuliÃ¨rement utile pour :
  - Cas limites
  - RÃ¨gles complexes
  - Reproduire un style spÃ©cifique

---

## ğŸ§® Comparaison : Calculatrice Simple vs AvancÃ©e

| CritÃ¨re                 | Calculatrice Simple                | Calculatrice AvancÃ©e                          |
|------------------------|------------------------------------|-----------------------------------------------|
| **Design**             | Basique, thÃ¨me clair               | Moderne, thÃ¨me sombre, ergonomie soignÃ©e      |
| **Structure du Code**  | Directe, dÃ©pend du texte des boutons | Professionnelle, usage de `data-action`, Ã©tat centralisÃ© |
| **Robustesse**         | LimitÃ©e, erreurs si clics rÃ©pÃ©tÃ©s  | Meilleure gestion des cas limites             |

**Conclusion** : La calculatrice avancÃ©e est plus **professionnelle, maintenable et fiable**.

---

## ğŸ§¹ Partie 3 : DÃ©bogage et Refactoring

### ğŸ§¼ Exercice 3.2 â€” Refactoring avec l'IA
**Code initial** :
- Algorithme : tri Ã  bulles
- ProblÃ¨mes :
  - Variables non explicites (`a, i, j`)
  - Aucune fonction
  - Pas de commentaire, code peu rÃ©utilisable

**IA a permis de** :
- Structurer le code avec fonctions
- Ajouter docstrings et lisibilitÃ©

---

### ğŸ“š Exercice 3.3 â€” Documentation GÃ©nÃ©rÃ©e

#### Fonction : `get_user_permissions(user_id, system_context)`
DÃ©termine les permissions utilisateur selon leur rÃ´le (Admin > Ã‰diteur > Utilisateur).

##### ğŸ“¥ ParamÃ¨tres
- `user_id` : int ou str
- `system_context` : dict avec :
```python
{
    'admins': {101, 105},
    'editors': {202, 304}
}
```

##### ğŸ“¤ Retour
- Liste des permissions (ex : `['read', 'write']`)

##### ğŸ“˜ Exemple :
```python
permissions_admin = get_user_permissions(101, system_roles)
# RÃ©sultat : ['read', 'write', 'delete', 'admin']
```

---

## âœ… Conclusion GÃ©nÃ©rale

- Un bon **prompt spÃ©cifique** amÃ©liore considÃ©rablement le code produit.
- Le **prompting par exemple (Few-Shot)** est crucial pour Ã©viter les erreurs subtiles.
- MÃªme avec une IA puissante, lâ€™interprÃ©tation dâ€™un prompt reste **sensible** : la formulation est clÃ©.
